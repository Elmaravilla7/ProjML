{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH1=\"C://Users//emiliocasella//Desktop//ProgettoML//testi-2//ham//\"\n",
    "PATH2=\"C://Users//emiliocasella//Desktop//ProgettoML//testi-2//spam//\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readFile(file):\n",
    "    f = open(file, encoding=\"latin-1\")\n",
    "    return f.read()\n",
    "\n",
    "def loadD(PATH1,PATH2):\n",
    "    data=[]\n",
    "    target=[]\n",
    "    fnames1=glob.glob(PATH1+'*.txt')\n",
    "    fnames2=glob.glob(PATH2+'*.txt')\n",
    "    for f1 in fnames1:\n",
    "        data.append(readFile(f1))\n",
    "        target.append(0)\n",
    "    for f2 in fnames2:\n",
    "        data.append(readFile(f2))\n",
    "        target.append(1)\n",
    "    \n",
    "    return pd.DataFrame(list(zip(data, target)), \n",
    "                        columns =['text', 'target']).sample(frac=1).reset_index(drop=True)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subject: you don _ t know how to get into sear...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subject: telephone interview with the enron re...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subject: re : bei enron\\nanjam ,\\ncan you , pl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subject: re :\\nscript language = javascript ty...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subject: copies everything - easy download or ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  Subject: you don _ t know how to get into sear...       1\n",
       "1  Subject: telephone interview with the enron re...       0\n",
       "2  Subject: re : bei enron\\nanjam ,\\ncan you , pl...       0\n",
       "3  Subject: re :\\nscript language = javascript ty...       1\n",
       "4  Subject: copies everything - easy download or ...       1"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=loadD(PATH1,PATH2)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import gensim\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "def prep_text(text):\n",
    "        text = text.lower()\n",
    "        text = re.sub('\\[.*?\\]', '', text)\n",
    "        text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "        text = re.sub('<.*?>+', '', text)\n",
    "        text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "        text = re.sub('\\n', '', text)\n",
    "        text = re.sub('\\w*\\d\\w*', '', text)\n",
    "        tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
    "        text=tokenizer.tokenize(text)\n",
    "        stop_words = stopwords.words('english')\n",
    "        text=remove_stopwords(text,stop_words)\n",
    "        return ' '.join(text)\n",
    "    \n",
    "def remove_stopwords(text,stop_words):\n",
    "    words = [w for w in text if w not in stop_words]\n",
    "    return words\n",
    "\n",
    "class MyTokenizer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X,y):\n",
    "        for c in y:\n",
    "            for i in range(0,len(X[c])):\n",
    "                X.at[i,c] =prep_text(X[c][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>subject nomination hpl dleivery eastrans nomin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>subject june statsit absolutely true get email...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>subject amazon com accountno interest payments...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>subject quality life decisionsfirings dudley b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>subject escute nossa r치dio agora mesmo uma r치d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  subject nomination hpl dleivery eastrans nomin...       0\n",
       "1  subject june statsit absolutely true get email...       1\n",
       "2  subject amazon com accountno interest payments...       1\n",
       "3  subject quality life decisionsfirings dudley b...       1\n",
       "4  subject escute nossa r치dio agora mesmo uma r치d...       1"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MyTokenizer().transform(df1,['text'])\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "cores = multiprocessing.cpu_count()\n",
    "\n",
    "def convert_mean(text):\n",
    "    model=gensim.models.Word2Vec(size=100, min_count=0, workers=cores-1)\n",
    "    model.build_vocab(text)\n",
    "    vectors=model.wv.vectors\n",
    "    return vectors\n",
    "\n",
    "class Meanw2v(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X,y):\n",
    "        for c in y:\n",
    "            for i in range(0,len(X[c])):\n",
    "                X.at[i,c] =convert_mean(X[c][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[-0.004773614, -0.0043040975, 0.0019556393, 0...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[-0.004773614, -0.0043040975, 0.0019556393, 0...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[-0.004773614, -0.0043040975, 0.0019556393, 0...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[-0.004773614, -0.0043040975, 0.0019556393, 0...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[-0.004773614, -0.0043040975, 0.0019556393, 0...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  [[-0.004773614, -0.0043040975, 0.0019556393, 0...       0\n",
       "1  [[-0.004773614, -0.0043040975, 0.0019556393, 0...       1\n",
       "2  [[-0.004773614, -0.0043040975, 0.0019556393, 0...       1\n",
       "3  [[-0.004773614, -0.0043040975, 0.0019556393, 0...       1\n",
       "4  [[-0.004773614, -0.0043040975, 0.0019556393, 0...       1"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfw2v=df1.copy()\n",
    "Meanw2v().transform(dfw2v,['text'])\n",
    "dfw2v.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from PIL import Image as I\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from collections import Counter\n",
    "from sklearn.linear_model import SGDClassifier,LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score,f1_score,roc_auc_score,precision_score,recall_score\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers  \n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "import pickle as pkl\n",
    "import warnings\n",
    "from tensorflow.keras.models import model_from_json\n",
    "from tensorflow.keras.layers import Dense, Activation,Conv2D,MaxPooling2D,Flatten,Dropout\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import metrics\n",
    "import matplotlib\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveM(model,fname):\n",
    "    fname=fname+'.model'\n",
    "    pkl.dump(model, open(fname, 'wb'))\n",
    "\n",
    "def loadM(fname):\n",
    "    return pkl.load(open(fname+'.model', 'rb'))\n",
    "\n",
    "def saveNN(model,fname):\n",
    "    json_model = model.model.to_json()\n",
    "    open('nn.json', 'w').write(json_model)\n",
    "    model.model.save_weights('nn.h5', overwrite=True)\n",
    "\n",
    "def loadNN(fname):\n",
    "    model = model_from_json(open(fname+'.json').read())\n",
    "    model.load_weights(fname+'.h5')\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def loadClass():\n",
    "    return pd.read_csv(\"C://Users//emiliocasella//Desktop//ProgettoML//10fold.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_network():\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Dense(64, activation='relu',input_dim=max_num_diff_words))\n",
    "    model.add(keras.layers.Dense(32, activation='relu'))\n",
    "    model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def compute_performance(estimators, X, y):\n",
    "    score_dict = {}\n",
    "    for e in estimators:\n",
    "        score_dict[e.__class__.__name__] = {}\n",
    "        cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "        score = cross_val_score(e, X ,y, cv=cv ,scoring='accuracy',n_jobs=-1)\n",
    "        score_dict[e.__class__.__name__]['accuracy/std'] = (np.round(np.mean(score),3),np.round(np.std(score),3))\n",
    "    return score_dict\n",
    "\n",
    "\n",
    "def tuningLR(X_train,y_train,logreg):\n",
    "    param_logreg_grid = [\n",
    "    {'penalty': ['l2'], 'solver': ['newton-cg', 'sag','lbfgs']},\n",
    "    ]\n",
    "    grid_search = GridSearchCV(logreg, param_logreg_grid, cv=10,\n",
    "                           scoring='accuracy', return_train_score=True)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    print(\"Best Param:\", grid_search.best_params_)\n",
    "    best_logreg = grid_search.best_estimator_\n",
    "    return best_logreg\n",
    "\n",
    "\n",
    "def tuningSGD(X_train,y_train,sgd):\n",
    "    param_sgd_grid = [\n",
    "    {'penalty': ['l2'], 'loss': ['hinge','log', 'squared_hinge', 'perceptron']},\n",
    "    ]\n",
    "    grid_search = GridSearchCV(sgd, param_sgd_grid, cv=10,\n",
    "                           scoring='accuracy', return_train_score=True)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    print(\"Best Param:\", grid_search.best_params_)\n",
    "    best_sgd = grid_search.best_estimator_\n",
    "    return best_sgd\n",
    "\n",
    "\n",
    "\n",
    "def tuningKNN(X_train,y_train,knn):\n",
    "    model = KNeighborsClassifier(n_jobs=-1)\n",
    "    params = {'n_neighbors':[4,5,6,7,8],\n",
    "          'weights':['distance'],\n",
    "          'algorithm':['auto']\n",
    "             }\n",
    "    grid_search = GridSearchCV(knn, params,scoring='accuracy',n_jobs=-1, cv=10)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    print(\"Best Param:\", grid_search.best_params_)\n",
    "    best_KNN = grid_search.best_estimator_\n",
    "    return best_KNN\n",
    "\n",
    "def tuningSVC(X_train,y_train,svc):\n",
    "    param_svc_grid ={'kernel': ['poly', 'linear', 'rbf','sigmoid'],\n",
    "                      'degree':[2]},\n",
    "    grid_search = GridSearchCV(svc, param_svc_grid,scoring='accuracy',n_jobs=-1, cv=10)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    print(\"Best Param:\", grid_search.best_params_)\n",
    "    best_svc = grid_search.best_estimator_\n",
    "    return best_svc\n",
    "\n",
    "\n",
    "class MyClassificatorTrain(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X,y):\n",
    "        X_train, X_test, y_train, y_test =train_test_split(X, y,\n",
    "                                                     test_size=0.2,shuffle=True)\n",
    "        print(\"Create models...\")\n",
    "        print(\"Tuning Logistic Regression...\")\n",
    "        logreg_clf = LogisticRegression(max_iter=1000)\n",
    "        logreg_clf.fit(X_train,y_train)\n",
    "        logreg_best=tuningLR(X_train,y_train,logreg_clf)\n",
    "        saveM(logreg_best,\"logreg\")\n",
    "        print(\"Tuning Stochastic Gradient Descent...\")\n",
    "        sgd_clf = SGDClassifier(max_iter=5, tol=-np.infty, random_state=42)\n",
    "        sgd_clf.fit(X_train,y_train)\n",
    "        sgd_best=tuningSGD(X_train,y_train,sgd_clf)\n",
    "        saveM(sgd_best,\"sgd\")\n",
    "        print(\"Gaussian...\")\n",
    "        nb_clf = GaussianNB()\n",
    "        nb_clf.fit(X_train,y_train)\n",
    "        saveM(nb_clf,\"nb\")\n",
    "        print(\"AdaBoost...\")\n",
    "        ada_clf=AdaBoostClassifier(DecisionTreeClassifier(max_depth=1),n_estimators=600, algorithm='SAMME.R',learning_rate=.5).fit(X_train,y_train)\n",
    "        saveM(ada_clf,\"ada\")\n",
    "        print(\"Tuning KNN...\")\n",
    "        knn_clf=KNeighborsClassifier(weights=\"distance\")\n",
    "        knn_clf.fit(X_train, y_train)\n",
    "        knn_best=tuningKNN(X_train,y_train,knn_clf)\n",
    "        saveM(knn_best,\"knn\")\n",
    "        print(\"Tuning SVC...\")\n",
    "        svc_clf=SVC(gamma='auto')\n",
    "        svc_clf.fit(X_train, y_train)\n",
    "        svc_best = tuningSVC(X_train,y_train,svc_clf)\n",
    "        saveM(svc_best,\"svc\")\n",
    "        print(\"Tuning NN...\")\n",
    "        nn_clf = KerasClassifier(build_fn=create_network, epochs=5, verbose=0)\n",
    "        nn_clf.fit(X_train,y_train)\n",
    "        saveNN(nn_clf,\"nn\")\n",
    "        print(\"All models Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MyClassificatorTrain().transform(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_clf=LogisticRegression(penalty='l2', solver='newton-cg', max_iter=1000)\n",
    "sgd_clf=SGDClassifier(loss=\"hinge\", penalty=\"l2\", max_iter=5, tol=-np.infty, random_state=42)\n",
    "nb_clf=GaussianNB()\n",
    "ada_clf=AdaBoostClassifier(DecisionTreeClassifier(max_depth=1),n_estimators=600, algorithm='SAMME.R',learning_rate=.5)\n",
    "knn_clf=KNeighborsClassifier(n_neighbors=4,algorithm='auto',weights=\"distance\")\n",
    "svc_clf=SVC(kernel='linear',degree=2)\n",
    "nn_clf = KerasClassifier(build_fn=create_network, epochs=5, verbose=0)\n",
    "score_dict=compute_performance([logreg_clf,sgd_clf,nb_clf,ada_clf,knn_clf,svc_clf,nn_clf], X, y)\n",
    "score_df = pd.DataFrame(score_dict)\n",
    "score_df.to_csv(\"C://Users//emiliocasella//Desktop//ProgettoML//10fold.csv\")\n",
    "score_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
